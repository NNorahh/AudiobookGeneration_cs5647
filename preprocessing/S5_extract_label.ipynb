{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from speakerDataset import create_dataloader\n",
    "from net.bert import extract_embeddings, load_model, save_embeddings_to_file\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for training set...\n",
      "Extracting embeddings for chunk_0.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:33<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_0.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_0.pt\n",
      "Extracting embeddings for chunk_1.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:34<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_1.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_1.pt\n",
      "Extracting embeddings for chunk_10.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 40/40 [00:11<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_10.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_10.pt\n",
      "Extracting embeddings for chunk_2.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:35<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_2.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_2.pt\n",
      "Extracting embeddings for chunk_3.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:35<00:00,  3.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_3.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_3.pt\n",
      "Extracting embeddings for chunk_4.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:35<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_4.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_4.pt\n",
      "Extracting embeddings for chunk_5.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:35<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_5.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_5.pt\n",
      "Extracting embeddings for chunk_6.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:36<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_6.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_6.pt\n",
      "Extracting embeddings for chunk_7.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:36<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_7.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_7.pt\n",
      "Extracting embeddings for chunk_8.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:36<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_8.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_8.pt\n",
      "Extracting embeddings for chunk_9.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting embeddings: 100%|██████████| 128/128 [00:35<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_9.pt\n",
      "Saved embeddings to C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_9.pt\n",
      "Embedding extraction and saving completed.\n",
      "Embedding extraction and saving completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from speakerDataset import create_dataloader\n",
    "from net.bert import extract_embeddings, load_model, save_embeddings_to_file\n",
    "import torch\n",
    "\n",
    "# Set dataset paths\n",
    "train_data_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\"\n",
    "val_data_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\val.json\"\n",
    "test_data_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\test.json\"\n",
    "\n",
    "# Ensure the output directory exists (in case needed for test/val)\n",
    "os.makedirs(train_data_path, exist_ok=True)\n",
    "\n",
    "# Load the model\n",
    "train_bert = False  # Set to True if you want to fine-tune BERT\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = load_model(train_bert=train_bert, device=device)\n",
    "\n",
    "def extract_and_save_train_embeddings(train_dir):\n",
    "    \"\"\"\n",
    "    Extracts embeddings for each JSON file in the train directory and saves them as .pt files.\n",
    "    \"\"\"\n",
    "    for filename in os.listdir(train_dir):\n",
    "        if filename.endswith('.json'):\n",
    "            json_path = os.path.join(train_dir, filename)\n",
    "            pt_path = os.path.join(train_dir, filename.replace('.json', '.pt'))\n",
    "\n",
    "            data_loader = create_dataloader(json_path, batch_size=16)\n",
    "\n",
    "            # Extract embeddings\n",
    "            print(f\"Extracting embeddings for {filename}...\")\n",
    "            embeddings = extract_embeddings(model, data_loader, device)\n",
    "\n",
    "            # Save the embeddings as .pt file\n",
    "            save_embeddings_to_file(embeddings, pt_path)\n",
    "            print(f\"Saved embeddings to {pt_path}\")\n",
    "\n",
    "# Extract and save train embeddings\n",
    "print(\"Extracting embeddings for training set...\")\n",
    "extract_and_save_train_embeddings(train_data_path)\n",
    "print(\"Embedding extraction and saving completed.\")\n",
    "\n",
    "# # Extract and save validation set embeddings\n",
    "# print(\"Extracting embeddings for validation set...\")\n",
    "# val_loader = create_dataloader(val_data_path, batch_size=16)\n",
    "# val_data = extract_embeddings(model, val_loader, device)\n",
    "# val_output_path = val_data_path.replace('.json', '.pt')\n",
    "# save_embeddings_to_file(val_data, val_output_path)\n",
    "\n",
    "# # Extract and save test set embeddings\n",
    "# print(\"Extracting embeddings for test set...\")\n",
    "# test_loader = create_dataloader(test_data_path, batch_size=16)\n",
    "# test_data = extract_embeddings(model, test_loader, device)\n",
    "# test_output_path = test_data_path.replace('.json', '.pt')\n",
    "# save_embeddings_to_file(test_data, test_output_path)\n",
    "\n",
    "print(\"Embedding extraction and saving completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "def process_and_save_embeddings_in_directory(directory_path, out_dir, is_single):\n",
    "    \"\"\"\n",
    "    Iterates through all .pt files in the given directory, applies masking to token embeddings \n",
    "    using target and speaker labels, and saves the updated entries back to the same files.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing .pt files.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Iterate through all .pt files in the directory\n",
    "        for filename in os.listdir(directory_path):\n",
    "            if filename.endswith(\".pt\"):\n",
    "                file_path = os.path.join(directory_path, filename)\n",
    "                print(f\"Processing {file_path}...\")\n",
    "\n",
    "                # Load the data from the .pt file\n",
    "                data_list = torch.load(file_path)\n",
    "                filtered_data_list = []\n",
    "                # Process each entry in the file\n",
    "                for entry_idx, entry in enumerate(data_list):\n",
    "                    if not entry['speaker_position']:\n",
    "                        print(f\"Removed entry {entry_idx} due to empty speaker positions.\")\n",
    "                        continue  # Skip this entry\n",
    "\n",
    "                    # Extract relevant fields\n",
    "                    token_embeddings = entry['token_embeddings']  # Shape: (seq_len, embedding_dim)\n",
    "                    target_position = entry['target_position']    # A single (start, end) tuple\n",
    "                    speaker_position = entry['speaker_position']  # List of (start, end) tuples\n",
    "\n",
    "                    seq_len, embedding_dim = token_embeddings.size()\n",
    "\n",
    "                    # Initialize speaker and target label masks\n",
    "                    speaker_labels = torch.zeros(seq_len)\n",
    "                    target_labels = torch.zeros(seq_len)\n",
    "\n",
    "                    if is_single:\n",
    "                        target_center = (target_position[0] + target_position[1]) / 2\n",
    "                    # Find the closest speaker position to the target position\n",
    "                        speaker_position = min(\n",
    "                            speaker_position,\n",
    "                            key=lambda pos: abs((pos[0] + pos[1]) / 2 - target_center)\n",
    "                        )\n",
    "\n",
    "                    # Use only the closest speaker position to generate speaker labels\n",
    "                        start, end = speaker_position\n",
    "                        if 0 <= start < seq_len and 0 <= end < seq_len and end - start + 1 <= 50:\n",
    "                            speaker_labels[start:end + 1] = 1  # Mark the closest speaker positions\n",
    "                    else:\n",
    "                        for (start, end) in speaker_position:\n",
    "                            if 0 <= start < seq_len and 0 <= end < seq_len and end - start + 1 <= 50:\n",
    "                                speaker_labels[start:end + 1] = 1  # Mark the closest speaker positions\n",
    "                    # # Generate target labels for the given (start, end) range\n",
    "                    t_start, t_end = target_position\n",
    "                    if 0 <= t_start < seq_len and 0 <= t_end < seq_len:\n",
    "                        target_labels[t_start:t_end + 1] = 1  # Mark the target range\n",
    "                    else:\n",
    "                        print(f\"Removed entry {entry_idx} due to invalid target positions.\")\n",
    "                        continue  # Skip this entry\n",
    "\n",
    "                    # Apply mask to extract target embeddings\n",
    "                    target_embeddings = token_embeddings * target_labels.unsqueeze(-1)\n",
    "\n",
    "                    # Add the new labels and embeddings to the entry\n",
    "                    entry['speaker_labels'] = speaker_labels\n",
    "                    entry['speaker_position'] = speaker_position\n",
    "                    entry['target_embeddings'] = target_embeddings\n",
    "\n",
    "                    # Add the processed entry to the filtered list\n",
    "                    filtered_data_list.append(entry)\n",
    "\n",
    "                out_path = os.path.join(out_dir, filename)\n",
    "                torch.save(filtered_data_list, out_path)\n",
    "                print(f\"Updated {file_path} saved successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_0.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_0.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_1.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_1.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_10.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_10.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_2.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_2.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_3.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_3.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_4.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_4.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_5.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_5.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_6.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_6.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_7.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_7.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_8.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_8.pt saved successfully.\n",
      "Processing C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_9.pt...\n",
      "Updated C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\\chunk_9.pt saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# multi\n",
    "directory_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\train\"\n",
    "out_dir = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\multi_label\\train\"\n",
    "process_and_save_embeddings_in_directory(directory_path, out_dir, is_single=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def process_and_save_embeddings(pt_file_path, output_file_path, is_single):\n",
    "    \"\"\"\n",
    "    Reads data from a .pt file with multiple entries, removes entries with empty speaker positions,\n",
    "    finds the closest speaker position to the target position, applies masking, and saves the updated entries.\n",
    "\n",
    "    Args:\n",
    "        pt_file_path (str): Path to the input .pt file containing individual entries.\n",
    "        output_file_path (str): Path to save the updated data with new embeddings.\n",
    "    \"\"\"\n",
    "    # Load the data from the .pt file (expected to be a list of entries)\n",
    "    data_list = torch.load(pt_file_path)\n",
    "\n",
    "    # Filter out entries with empty speaker positions\n",
    "    filtered_data_list = []\n",
    "    for entry_idx, entry in enumerate(data_list):\n",
    "        if not entry['speaker_position']:\n",
    "            print(f\"Removed entry {entry_idx} due to empty speaker positions.\")\n",
    "            continue  # Skip this entry\n",
    "\n",
    "        # Extract relevant fields\n",
    "        token_embeddings = entry['token_embeddings']  # Shape: (seq_len, embedding_dim)\n",
    "        target_position = entry['target_position']    # A single (start, end) tuple\n",
    "        speaker_position = entry['speaker_position']  # List of (start, end) tuples\n",
    "\n",
    "        seq_len, embedding_dim = token_embeddings.size()\n",
    "\n",
    "        # Initialize speaker and target label masks\n",
    "        speaker_labels = torch.zeros(seq_len)\n",
    "        target_labels = torch.zeros(seq_len)\n",
    "\n",
    "        if is_single:\n",
    "            target_center = (target_position[0] + target_position[1]) / 2\n",
    "            speaker_position = min(\n",
    "                speaker_position,\n",
    "                key=lambda pos: abs((pos[0] + pos[1]) / 2 - target_center)\n",
    "            )\n",
    "\n",
    "            start, end = speaker_position\n",
    "            if 0 <= start < seq_len and 0 <= end < seq_len and end - start + 1 <= 50:\n",
    "                speaker_labels[start:end + 1] = 1  # Mark the closest speaker positions\n",
    "        else:\n",
    "            for (start, end) in speaker_position:\n",
    "                if 0 <= start < seq_len and 0 <= end < seq_len and end - start + 1 <= 50:\n",
    "                    speaker_labels[start:end + 1] = 1\n",
    "\n",
    "        t_start, t_end = target_position\n",
    "        if 0 <= t_start < seq_len and 0 <= t_end < seq_len:\n",
    "            target_labels[t_start:t_end + 1] = 1  # Mark the target range\n",
    "        else:\n",
    "            print(f\"Removed entry {entry_idx} due to invalid target positions.\")\n",
    "            continue  # Skip this entry\n",
    "\n",
    "        # Apply mask to extract target embeddings\n",
    "        target_embeddings = token_embeddings * target_labels.unsqueeze(-1)\n",
    "\n",
    "        # Add the new labels and embeddings to the entry\n",
    "        entry['speaker_labels'] = speaker_labels\n",
    "        entry['speaker_position'] = speaker_position\n",
    "        entry['target_embeddings'] = target_embeddings\n",
    "\n",
    "        # Add the processed entry to the filtered list\n",
    "        filtered_data_list.append(entry)\n",
    "\n",
    "    # Save the updated data back to a new .pt file\n",
    "    torch.save(filtered_data_list, output_file_path)\n",
    "\n",
    "    print(f\"Updated data with embeddings saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data with embeddings saved to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\single_label\\val.pt\n"
     ]
    }
   ],
   "source": [
    "pt_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\val.pt\"\n",
    "output_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\single_label\\val.pt\"\n",
    "process_and_save_embeddings(pt_file_path, output_file_path, is_single=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data with embeddings saved to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\multi_label\\val.pt\n",
      "Updated data with embeddings saved to: C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\multi_label\\test.pt\n"
     ]
    }
   ],
   "source": [
    "pt_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\val.pt\"\n",
    "output_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\multi_label\\val.pt\"\n",
    "process_and_save_embeddings(pt_file_path, output_file_path, is_single=False)\n",
    "pt_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\test.pt\"\n",
    "output_file_path = r\"C:\\Users\\Lenovo\\OneDrive\\NUS\\CS-24fall\\project\\AudiobookGeneration_cs5647\\Dataset_SID_001\\multi_label\\test.pt\"\n",
    "process_and_save_embeddings(pt_file_path, output_file_path, is_single=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
